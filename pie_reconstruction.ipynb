{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN8kzoSzCCe0WiIW9Vp4+tl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Grok"],"metadata":{"id":"2kJ9Hmpa3Pyc"}},{"cell_type":"code","source":["!pip install paddlepaddle\n","!pip install paddleocr"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FsAc3gN8pN4X","executionInfo":{"status":"ok","timestamp":1740480329196,"user_tz":-345,"elapsed":26875,"user":{"displayName":"Sangam Parajuli","userId":"11167898404134312443"}},"outputId":"8a8be1ab-62b1-42eb-e86e-787206fe2ada"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting paddlepaddle\n","  Downloading paddlepaddle-2.6.2-cp311-cp311-manylinux1_x86_64.whl.metadata (8.6 kB)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from paddlepaddle) (0.28.1)\n","Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.11/dist-packages (from paddlepaddle) (1.26.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from paddlepaddle) (11.1.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from paddlepaddle) (4.4.2)\n","Collecting astor (from paddlepaddle)\n","  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n","Collecting opt-einsum==3.3.0 (from paddlepaddle)\n","  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from paddlepaddle) (4.25.6)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle) (1.0.7)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle) (3.10)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->paddlepaddle) (0.14.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->paddlepaddle) (1.3.1)\n","Downloading paddlepaddle-2.6.2-cp311-cp311-manylinux1_x86_64.whl (126.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n","Installing collected packages: opt-einsum, astor, paddlepaddle\n","  Attempting uninstall: opt-einsum\n","    Found existing installation: opt_einsum 3.4.0\n","    Uninstalling opt_einsum-3.4.0:\n","      Successfully uninstalled opt_einsum-3.4.0\n","Successfully installed astor-0.8.1 opt-einsum-3.3.0 paddlepaddle-2.6.2\n","Collecting paddleocr\n","  Downloading paddleocr-2.9.1-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from paddleocr) (2.0.7)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from paddleocr) (0.25.2)\n","Requirement already satisfied: imgaug in /usr/local/lib/python3.11/dist-packages (from paddleocr) (0.4.0)\n","Collecting pyclipper (from paddleocr)\n","  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n","Collecting lmdb (from paddleocr)\n","  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.67.1)\n","Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (from paddleocr) (1.26.4)\n","Collecting rapidfuzz (from paddleocr)\n","  Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.11.0.86)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.11.0.86)\n","Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from paddleocr) (3.0.12)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from paddleocr) (11.1.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from paddleocr) (6.0.2)\n","Collecting python-docx (from paddleocr)\n","  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.13.3)\n","Requirement already satisfied: fonttools>=4.24.0 in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.56.0)\n","Collecting fire>=0.3.0 (from paddleocr)\n","  Downloading fire-0.7.0.tar.gz (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from paddleocr) (2.32.3)\n","Collecting albumentations==1.4.10 (from paddleocr)\n","  Downloading albumentations-1.4.10-py3-none-any.whl.metadata (38 kB)\n","Collecting albucore==0.0.13 (from paddleocr)\n","  Downloading albucore-0.0.13-py3-none-any.whl.metadata (3.1 kB)\n","Collecting tomli>=2.0.1 (from albucore==0.0.13->paddleocr)\n","  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.13->paddleocr) (4.12.2)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.13->paddleocr) (4.11.0.86)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->paddleocr) (1.13.1)\n","Requirement already satisfied: scikit-learn>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->paddleocr) (1.6.1)\n","Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->paddleocr) (2.10.6)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.3.0->paddleocr) (2.5.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (3.4.2)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (2025.2.18)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (24.2)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (0.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->paddleocr) (2.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from imgaug->paddleocr) (1.17.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from imgaug->paddleocr) (3.10.0)\n","Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx->paddleocr) (5.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr) (2025.1.31)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr) (2.27.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr) (3.5.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug->paddleocr) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug->paddleocr) (0.12.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug->paddleocr) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug->paddleocr) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug->paddleocr) (2.8.2)\n","Downloading paddleocr-2.9.1-py3-none-any.whl (544 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m544.7/544.7 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading albucore-0.0.13-py3-none-any.whl (8.5 kB)\n","Downloading albumentations-1.4.10-py3-none-any.whl (161 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.9/161.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=45bce2d83a2d2d1655726e1c3e76a9acfa549374c8fb9441f9cc4158be357144\n","  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n","Successfully built fire\n","Installing collected packages: pyclipper, lmdb, tomli, rapidfuzz, python-docx, fire, albucore, albumentations, paddleocr\n","  Attempting uninstall: albucore\n","    Found existing installation: albucore 0.0.23\n","    Uninstalling albucore-0.0.23:\n","      Successfully uninstalled albucore-0.0.23\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 2.0.4\n","    Uninstalling albumentations-2.0.4:\n","      Successfully uninstalled albumentations-2.0.4\n","Successfully installed albucore-0.0.13 albumentations-1.4.10 fire-0.7.0 lmdb-1.6.2 paddleocr-2.9.1 pyclipper-1.3.0.post6 python-docx-1.1.2 rapidfuzz-3.12.1 tomli-2.2.1\n"]}]},{"cell_type":"code","source":["from paddleocr import PaddleOCR, draw_ocr\n","from PIL import Image\n","import csv\n","import os\n","import urllib.request\n","import json\n","\n","\n","\n","img_path = '/content/checkpie.png'\n","\n","def get_font():\n","    \"\"\"Download a font file if it doesn't exist and return the path.\"\"\"\n","    font_path = \"DejaVuSans.ttf\"\n","    if not os.path.exists(font_path):\n","        font_url = \"https://github.com/PaddlePaddle/PaddleOCR/raw/release/2.6/doc/fonts/simfang.ttf\"\n","        try:\n","            urllib.request.urlretrieve(font_url, font_path)\n","        except Exception as e:\n","            # Fallback to a different font if the first one fails\n","            fallback_url = \"https://github.com/opensourcedesign/fonts/raw/master/gnu-freefont_freesans/FreeSans.ttf\"\n","            urllib.request.urlretrieve(fallback_url, font_path)\n","    return font_path\n","\n","def merge_nearby_texts(detections, vertical_threshold=20, horizontal_overlap_threshold=0.5):\n","    \"\"\"\n","    Merge nearby OCR detections for non-percentage text.\n","\n","    Two detections will be merged if:\n","      - They do NOT contain \"%\" in their text.\n","      - The vertical gap between the previous box’s bottom and the current box’s top is <= vertical_threshold.\n","      - Their horizontal boxes overlap significantly (overlap ratio >= horizontal_overlap_threshold).\n","\n","    The merged detection will combine the texts (separated by a space) and the bounding boxes will be the union.\n","    \"\"\"\n","    # Sort detections by the top coordinate (minimum y of the box)\n","    sorted_dets = sorted(detections, key=lambda d: min(pt[1] for pt in d[\"box\"]))\n","    merged = []\n","    for det in sorted_dets:\n","        # Do not merge if text is a percentage value (or contains \"%\")\n","        if \"%\" in det[\"text\"]:\n","            merged.append(det)\n","        else:\n","            # If there is an existing merged detection that is also non-percentage,\n","            # try to merge this detection with it.\n","            if merged and (\"%\" not in merged[-1][\"text\"]):\n","                last_det = merged[-1]\n","                # Compute bounding box for last detection\n","                last_box = last_det[\"box\"]\n","                last_x1 = min(pt[0] for pt in last_box)\n","                last_y1 = min(pt[1] for pt in last_box)\n","                last_x2 = max(pt[0] for pt in last_box)\n","                last_y2 = max(pt[1] for pt in last_box)\n","\n","                # Current detection box\n","                curr_box = det[\"box\"]\n","                curr_x1 = min(pt[0] for pt in curr_box)\n","                curr_y1 = min(pt[1] for pt in curr_box)\n","                curr_x2 = max(pt[0] for pt in curr_box)\n","                curr_y2 = max(pt[1] for pt in curr_box)\n","\n","                # Determine vertical gap between last box's bottom and current box's top\n","                vertical_gap = curr_y1 - last_y2\n","\n","                # Compute horizontal overlap\n","                horizontal_overlap = max(0, min(last_x2, curr_x2) - max(last_x1, curr_x1))\n","                last_width = last_x2 - last_x1\n","                curr_width = curr_x2 - curr_x1\n","                min_width = min(last_width, curr_width)\n","                overlap_ratio = horizontal_overlap / min_width if min_width > 0 else 0\n","\n","                # If the boxes are close vertically and overlap horizontally, merge them\n","                if vertical_gap <= vertical_threshold and overlap_ratio >= horizontal_overlap_threshold:\n","                    merged_text = last_det[\"text\"] + \" \" + det[\"text\"]\n","                    # Create union box (simple min/max over coordinates)\n","                    union_box = [\n","                        [min(last_x1, curr_x1), min(last_y1, curr_y1)],\n","                        [max(last_x2, curr_x2), min(last_y1, curr_y1)],\n","                        [max(last_x2, curr_x2), max(last_y2, curr_y2)],\n","                        [min(last_x1, curr_x1), max(last_y2, curr_y2)]\n","                    ]\n","                    merged[-1] = {\n","                        \"box\": union_box,\n","                        \"text\": merged_text,\n","                        \"confidence\": (last_det[\"confidence\"] + det[\"confidence\"]) / 2\n","                    }\n","                else:\n","                    merged.append(det)\n","            else:\n","                merged.append(det)\n","    return merged\n","\n","# Initialize PaddleOCR\n","ocr = PaddleOCR(use_angle_cls=True, lang=\"en\")\n","\n","# Path to image\n","# img_path = '/content/none pie.jpeg'\n","\n","# Perform OCR\n","result = ocr.ocr(img_path, cls=True)\n","\n","# Extract results from the first (and only) page\n","detections = result[0]\n","\n","# Extract boxes, texts, and scores\n","boxes = [detection[0] for detection in detections]\n","txts = [detection[1][0] for detection in detections]\n","scores = [detection[1][1] for detection in detections]\n","\n","# Build a list of detection dictionaries\n","raw_detections = []\n","for box, text, score in zip(boxes, txts, scores):\n","    raw_detections.append({\n","        \"box\": box,\n","        \"text\": text,\n","        \"confidence\": float(f\"{score:.4f}\")\n","    })\n","\n","# Merge detections that belong together (only for non-percentage texts)\n","merged_detections = merge_nearby_texts(raw_detections)\n","\n","# Get font path for drawing results\n","font_path = get_font()\n","\n","# Draw OCR results on image\n","try:\n","    image = Image.open(img_path).convert('RGB')\n","    im_show = draw_ocr(image, [det[\"box\"] for det in merged_detections],\n","                         [det[\"text\"] for det in merged_detections],\n","                         [det[\"confidence\"] for det in merged_detections],\n","                         font_path=font_path)\n","    im_show = Image.fromarray(im_show)\n","    im_show.save('result.jpg')\n","except Exception as e:\n","    print(f\"Warning: Could not draw OCR results on image: {e}\")\n","\n","# Optionally, you can also save to CSV or a text file.\n","# Here we save the merged results to a JSON file.\n","with open('ocr_results3.json', 'w', encoding='utf-8') as jsonfile:\n","    json.dump(merged_detections, jsonfile, ensure_ascii=False, indent=4)\n","\n","print(\"OCR processing completed. Check result.jpg and ocr_results.json\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13pxUwnPpPmJ","executionInfo":{"status":"ok","timestamp":1740482930833,"user_tz":-345,"elapsed":3306,"user":{"displayName":"Sangam Parajuli","userId":"11167898404134312443"}},"outputId":"f14882e4-f193-49df-8116-a343d07e3e1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2025/02/25 11:28:49] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.11/dist-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n","[2025/02/25 11:28:52] ppocr DEBUG: dt_boxes num : 6, elapsed : 0.0679934024810791\n","[2025/02/25 11:28:52] ppocr DEBUG: cls num  : 6, elapsed : 0.020972251892089844\n","[2025/02/25 11:28:52] ppocr DEBUG: rec_res num  : 6, elapsed : 0.42820024490356445\n","OCR processing completed. Check result.jpg and ocr_results.json\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ulyF6jE63Kj0","executionInfo":{"status":"ok","timestamp":1740483109906,"user_tz":-345,"elapsed":362,"user":{"displayName":"Sangam Parajuli","userId":"11167898404134312443"}},"outputId":"451ccca2-da59-4748-e418-eb4dc4b1e838"},"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","    \"title\": \"hello\",\n","    \"pie_center\": [\n","        203,\n","        238\n","    ],\n","    \"slices\": [\n","        {\n","            \"label\": \"case\",\n","            \"percentage\": 21.11,\n","            \"color\": [\n","                16,\n","                207,\n","                233\n","            ],\n","            \"start_angle\": 18.13018691250096,\n","            \"end_angle\": 308.6598082540901,\n","            \"pixel_count\": 2111\n","        },\n","        {\n","            \"label\": \"mudda\",\n","            \"percentage\": 19.139999999999997,\n","            \"color\": [\n","                204,\n","                6,\n","                203\n","            ],\n","            \"start_angle\": 201.6055272426385,\n","            \"end_angle\": 270.0,\n","            \"pixel_count\": 1914\n","        },\n","        {\n","            \"label\": \"rabi\",\n","            \"percentage\": 9.3,\n","            \"color\": [\n","                0,\n","                197,\n","                58\n","            ],\n","            \"start_angle\": 271.1017061152064,\n","            \"end_angle\": 305.92294619907057,\n","            \"pixel_count\": 930\n","        },\n","        {\n","            \"label\": \"sahakari\",\n","            \"percentage\": 31.019999999999996,\n","            \"color\": [\n","                210,\n","                239,\n","                8\n","            ],\n","            \"start_angle\": 306.3136454187634,\n","            \"end_angle\": 125.29334759066029,\n","            \"pixel_count\": 3102\n","        },\n","        {\n","            \"label\": \"lamichane\",\n","            \"percentage\": 19.43,\n","            \"color\": [\n","                255,\n","                64,\n","                1\n","            ],\n","            \"start_angle\": 306.6656354826422,\n","            \"end_angle\": 17.671050361992002,\n","            \"pixel_count\": 1943\n","        }\n","    ]\n","}\n"]}],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import json\n","import os\n","import math\n","from typing import List, Tuple, Dict, Optional\n","\n","class PieChartError(Exception):\n","    \"\"\"Custom exception for pie chart processing errors\"\"\"\n","    pass\n","\n","def is_numerical(text: str) -> bool:\n","    \"\"\"Check if text is a numerical value (with or without percentage)\"\"\"\n","    text = text.strip().replace('%', '').replace(',', '.').strip()\n","    try:\n","        float(text)\n","        return True\n","    except ValueError:\n","        return False\n","\n","def get_angle(point: Tuple[float, float], center: Tuple[int, int]) -> float:\n","    \"\"\"Calculate the angle between a point and the center in degrees\"\"\"\n","    dx = point[0] - center[0]\n","    dy = point[1] - center[1]\n","    return (np.degrees(np.arctan2(dy, dx)) + 360) % 360\n","\n","def kmeans_numpy(X, n_clusters, max_iter=100, n_init=5):\n","    \"\"\"K-means clustering implementation using NumPy\"\"\"\n","    best_inertia = float('inf')\n","    best_centers = None\n","    best_labels = None\n","\n","    for _ in range(n_init):\n","        if len(X) <= n_clusters:\n","            centers = X.copy().astype(np.float64)\n","            labels = np.arange(len(X))\n","            return type('KMeansResult', (), {'cluster_centers_': centers, 'labels_': labels})()\n","\n","        idx = np.random.choice(len(X), n_clusters, replace=False)\n","        centers = X[idx].astype(np.float64)\n","\n","        for _ in range(max_iter):\n","            distances = np.sqrt(((X[:, np.newaxis] - centers) ** 2).sum(axis=2))\n","            labels = np.argmin(distances, axis=1)\n","            new_centers = np.empty_like(centers)\n","            for k in range(n_clusters):\n","                if np.any(labels == k):\n","                    new_centers[k] = X[labels == k].mean(axis=0)\n","                else:\n","                    new_centers[k] = centers[k]\n","            if np.allclose(centers, new_centers):\n","                break\n","            centers = new_centers\n","\n","        inertia = np.sum((X - centers[labels]) ** 2)\n","        if inertia < best_inertia:\n","            best_inertia = inertia\n","            best_centers = centers\n","            best_labels = labels\n","\n","    return type('KMeansResult', (), {\n","        'cluster_centers_': best_centers,\n","        'labels_': best_labels\n","    })()\n","\n","def extract_segment_info(\n","    image: np.ndarray,\n","    mask: np.ndarray,\n","    pie_center: Tuple[int, int],\n","    expected_segments: int\n",") -> List[Dict]:\n","    \"\"\"Extract segment information including centroids from the pie chart\"\"\"\n","    y_coords, x_coords = np.nonzero(mask)\n","    max_pixels = 10000\n","    if len(y_coords) > max_pixels:\n","        sample_indices = np.random.choice(len(y_coords), max_pixels, replace=False)\n","        y_coords = y_coords[sample_indices]\n","        x_coords = x_coords[sample_indices]\n","    pixels = image[y_coords, x_coords]\n","\n","    if len(pixels) < expected_segments:\n","        expected_segments = max(1, len(pixels) // 10)\n","\n","    kmeans = kmeans_numpy(pixels, n_clusters=expected_segments)\n","    angles = np.degrees(np.arctan2(y_coords - pie_center[1], x_coords - pie_center[0]))\n","    angles = (angles + 360) % 360\n","    pixel_labels = kmeans.labels_\n","\n","    segments = []\n","    for i in range(expected_segments):\n","        segment_mask = pixel_labels == i\n","        segment_x = x_coords[segment_mask]\n","        segment_y = y_coords[segment_mask]\n","        if len(segment_x) == 0:\n","            continue\n","        centroid_x = np.mean(segment_x)\n","        centroid_y = np.mean(segment_y)\n","        segment_angles = angles[segment_mask]\n","        start_angle = np.min(segment_angles)\n","        end_angle = np.max(segment_angles)\n","        # Handle wrap-around segments\n","        if end_angle - start_angle > 330:\n","            sorted_angles = np.sort(segment_angles)\n","            gaps = sorted_angles[1:] - sorted_angles[:-1]\n","            if len(gaps) > 0:\n","                max_gap_idx = np.argmax(gaps)\n","                start_angle = sorted_angles[max_gap_idx + 1]\n","                end_angle = sorted_angles[max_gap_idx]\n","        segments.append({\n","            'start_angle': float(start_angle),\n","            'end_angle': float(end_angle),\n","            'color': kmeans.cluster_centers_[i].astype(int),\n","            'pixel_count': int(np.sum(segment_mask)),\n","            'centroid': (float(centroid_x), float(centroid_y))\n","        })\n","\n","    segments.sort(key=lambda x: x['start_angle'])\n","    return segments\n","\n","def match_labels_and_get_title(\n","    text_regions: List[Dict],\n","    pie_center: Tuple[int, int]\n",") -> Tuple[List[str], List[float], str]:\n","    \"\"\"Match labels with percentages and determine the title when percentages are present\"\"\"\n","    numericals = []\n","    non_numericals = []\n","    for region in text_regions:\n","        if is_numerical(region['text']):\n","            numericals.append(region)\n","        else:\n","            non_numericals.append(region)\n","\n","    pairs = []\n","    used_non_numericals = []\n","    for num in numericals:\n","        candidate_non_numericals = [nn for nn in non_numericals if nn not in used_non_numericals]\n","        if not candidate_non_numericals:\n","            raise PieChartError(f\"Unpaired numerical value: {num['text']}\")\n","        closest = min(\n","            candidate_non_numericals,\n","            key=lambda nn: math.hypot(\n","                num['center'][0] - nn['center'][0],\n","                num['center'][1] - nn['center'][1]\n","            )\n","        )\n","        pairs.append((closest, num))\n","        used_non_numericals.append(closest)\n","\n","    labels = [pair[0]['text'] for pair in pairs]\n","    percentages = [float(pair[1]['text'].strip('%')) for pair in pairs]\n","    title_candidates = [nn for nn in non_numericals if nn not in used_non_numericals]\n","    title = \" \".join([tc['text'] for tc in title_candidates]) if title_candidates else \"Pie Chart\"\n","    return labels, percentages, title\n","\n","def process_pie_chart(\n","    image_path: str,\n","    paddle_results: List[Dict],\n","    save_path: Optional[str] = None\n",") -> Dict:\n","    \"\"\"Process the pie chart image and extract data\"\"\"\n","    try:\n","        # Load and preprocess image\n","        image = cv2.imread(image_path)\n","        if image is None:\n","            raise PieChartError(\"Image load failed\")\n","\n","        max_dim = 1000\n","        h, w = image.shape[:2]\n","        if max(h, w) > max_dim:\n","            scale = max_dim / max(h, w)\n","            image = cv2.resize(image, (int(w * scale), int(h * scale)))\n","\n","        # Detect pie chart contour\n","        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        _, binary = cv2.threshold(gray, 250, 255, cv2.THRESH_BINARY_INV)\n","        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","        if not contours:\n","            sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)\n","            sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)\n","            sobel = cv2.magnitude(sobelx, sobely)\n","            sobel = np.uint8(sobel)\n","            _, binary = cv2.threshold(sobel, 50, 255, cv2.THRESH_BINARY)\n","            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","            if not contours:\n","                raise PieChartError(\"No pie chart detected in image\")\n","\n","        pie_contour = max(contours, key=cv2.contourArea)\n","        mask = np.zeros_like(gray)\n","        cv2.drawContours(mask, [pie_contour], -1, 255, -1)\n","        moments = cv2.moments(mask)\n","        if moments['m00'] == 0:\n","            raise PieChartError(\"Invalid pie chart contour moments\")\n","        pie_center = (int(moments['m10'] / moments['m00']), int(moments['m01'] / moments['m00']))\n","\n","        # Process OCR results\n","        text_regions = []\n","        for result in paddle_results:\n","            if result.get('confidence', 1) <= 0.5:\n","                continue\n","            box = result['box']\n","            x_coords = [pt[0] for pt in box]\n","            y_coords = [pt[1] for pt in box]\n","            x_min, y_min = min(x_coords), min(y_coords)\n","            x_max, y_max = max(x_coords), max(y_coords)\n","            text_regions.append({\n","                'text': result['text'],\n","                'center': ((x_min + x_max) / 2.0, (y_min + y_max) / 2.0),\n","                'bbox': (x_min, y_min, x_max - x_min, y_max - y_min)\n","            })\n","\n","        has_percentage = any(is_numerical(r['text']) and ('%' in r['text']) for r in text_regions)\n","\n","        if has_percentage:\n","            labels, percentages, title = match_labels_and_get_title(text_regions, pie_center)\n","            expected_segments = len(percentages)\n","        else:\n","            # Handle case without percentages\n","            if text_regions:\n","                top_text = min(text_regions, key=lambda r: r['center'][1])\n","                title = top_text['text']\n","                non_title_regions = [r for r in text_regions if r is not top_text]\n","            else:\n","                title = \"Pie Chart\"\n","                non_title_regions = []\n","            expected_segments = len(non_title_regions) if non_title_regions else 3\n","\n","        if expected_segments < 2:\n","            expected_segments = 2\n","\n","        # Extract segments with centroids\n","        segments = extract_segment_info(\n","            cv2.cvtColor(image, cv2.COLOR_BGR2RGB),\n","            mask,\n","            pie_center,\n","            expected_segments\n","        )\n","        if not segments:\n","            segments = [{\n","                'start_angle': 0,\n","                'end_angle': 360,\n","                'color': np.array([200, 200, 200]),\n","                'pixel_count': 100,\n","                'centroid': pie_center\n","            }]\n","\n","        if has_percentage:\n","            # Use OCR-provided percentages and labels\n","            pass\n","        else:\n","            # Compute percentages from pixel counts\n","            total_pixels = sum(seg['pixel_count'] for seg in segments)\n","            percentages = [seg['pixel_count'] / total_pixels * 100 for seg in segments]\n","\n","            # Compute pie radius\n","            distances = [math.hypot(pt[0][0] - pie_center[0], pt[0][1] - pie_center[1]) for pt in pie_contour]\n","            radius = np.mean(distances)\n","\n","            # Add mid-angle to segments\n","            for seg in segments:\n","                seg['mid_angle'] = (seg['start_angle'] + seg['end_angle']) / 2.0\n","\n","            # Compute angles for text regions\n","            for text_region in non_title_regions:\n","                text_region['angle'] = get_angle(text_region['center'], pie_center)\n","\n","            # Match segments to text regions using distance and angle\n","            pairs = []\n","            for seg_idx, seg in enumerate(segments):\n","                for text_idx, text_region in enumerate(non_title_regions):\n","                    distance = math.hypot(seg['centroid'][0] - text_region['center'][0],\n","                                        seg['centroid'][1] - text_region['center'][1])\n","                    angular_diff = min(abs(seg['mid_angle'] - text_region['angle']),\n","                                     360 - abs(seg['mid_angle'] - text_region['angle']))\n","                    score = (distance / radius) + (angular_diff / 180)\n","                    pairs.append((score, seg_idx, text_idx))\n","\n","            # Sort pairs by score (lower is better)\n","            pairs.sort(key=lambda x: x[0])\n","\n","            # Assign labels to segments\n","            assigned_labels = [None] * len(segments)\n","            used_text_indices = set()\n","            for score, seg_idx, text_idx in pairs:\n","                if assigned_labels[seg_idx] is None and text_idx not in used_text_indices:\n","                    assigned_labels[seg_idx] = non_title_regions[text_idx]['text']\n","                    used_text_indices.add(text_idx)\n","\n","            # Assign default labels to unmatched segments\n","            for i in range(len(segments)):\n","                if assigned_labels[i] is None:\n","                    assigned_labels[i] = f\"Segment {i+1}\"\n","\n","            labels = assigned_labels\n","\n","        # Compile chart data\n","        chart_data = {\n","            \"title\": title,\n","            \"pie_center\": list(pie_center),\n","            \"slices\": []\n","        }\n","        for i, seg in enumerate(segments):\n","            label = labels[i] if i < len(labels) else f\"Segment {i+1}\"\n","            perc = percentages[i] if i < len(percentages) else 0.0\n","            chart_data[\"slices\"].append({\n","                \"label\": label,\n","                \"percentage\": float(perc),\n","                \"color\": seg['color'].tolist(),\n","                \"start_angle\": float(seg['start_angle']),\n","                \"end_angle\": float(seg['end_angle']),\n","                \"pixel_count\": int(seg['pixel_count'])\n","            })\n","\n","        # Save results\n","        base_path = save_path if save_path else os.path.splitext(image_path)[0]\n","        json_path = f\"{base_path}_data.json\"\n","        with open(json_path, 'w') as f:\n","            json.dump(chart_data, f, indent=4)\n","\n","        # Generate and save reconstructed pie chart\n","        plt.figure(figsize=(10, 10))\n","        normalized_colors = [seg['color'] / 255.0 for seg in segments]\n","        plt.pie(\n","            percentages,\n","            labels=labels,\n","            colors=normalized_colors,\n","            autopct='%1.1f%%',\n","            startangle=90\n","        )\n","        plt.title(title)\n","        plt.savefig(f\"{base_path}_reconstruction.png\")\n","        plt.close()\n","\n","        return chart_data\n","\n","    except Exception as e:\n","        print(f\"Error processing pie chart: {str(e)}\")\n","        return None\n","\n","if __name__ == \"__main__\":\n","    image_path = \"/content/pie_1000.png\"  # Replace with your image path\n","    with open(\"/content/pie_1000.json\", \"r\") as f:  # Replace with your OCR results path\n","        paddle_results = json.load(f)\n","    result = process_pie_chart(image_path, paddle_results, save_path=\"output_chart\")\n","    if result:\n","        print(json.dumps(result, indent=4))"]}]}